# -*- coding: utf-8 -*-
"""TCC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GBgjCCKsPPgnttCDQ4jB2RcceHDw8vFJ
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Importing modules"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler
from sklearn.model_selection import StratifiedKFold
from sklearn.manifold import TSNE

from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn import svm
from sklearn.linear_model import LogisticRegression

"""# Data loading"""

f = open("/content/drive/MyDrive/Laura Speggiorin - TCC/GSE123302_series_matrix.txt/GSE123302_series_matrix.txt", "r")

data = f.readlines()

header_str = data[69]
class_str = data[42]
matrix_str = data[70:-1]

header = header_str.replace("\"", "")
header = header.replace("\n", "")
header = header.replace("ID_REF\t", "")

header = header.split("\t")

#header

classes = class_str.replace("\"", "")
classes = classes.replace("\n", "")
classes = classes.replace("!Sample_characteristics_ch1\t", "")
classes = classes.replace("diagnosis: ", "")

classes = classes.split("\t")

classes[0:5]

# for i in range(len(matrix_str)): matrix_str[i] = matrix_str[i].replace("\n", "")

matrix_str = [matrix_str[i].replace("\n", "") for i in range(len(matrix_str))]

header.insert(0,"ID")
df = []
string = ""
for i in range(len(matrix_str)):
  string = matrix_str[i]
  df.append(string.split("\t"))

df = pd.DataFrame(df)
df.columns = header
df.set_index('ID', inplace=True)

df

df_t = df.transpose()
df_t.head()

# plot dos atributos pre transformação
plot_df_atr = df_t.sample(100, axis='columns', random_state = 5).columns

sns.boxplot(data=df_t[plot_df_atr].astype("float64"))

plt.ylim(0,14)

plt.show()

#plot das instancias pré transformação
plot_df_ins = df.sample(100, axis='columns', random_state = 5).columns

sns.boxplot(data=df[plot_df_ins].astype("float64"))
plt.ylim(0,14)

plt.show()



# ------> Colocar legenda nas imagens

# transformação log2
transformed_df = np.log2(df_t.astype("float64") + 1.0)

#plot dos atributos pós transformação
sns.boxplot(data=transformed_df[plot_df_atr].astype("float64"))
plt.show()

sns.boxplot(data=transformed_df[plot_df_atr].astype("float64"))
plt.ylim(0,14)

plt.show()

#plot das instancia pós transformação
sns.boxplot(data=transformed_df.transpose()[plot_df_ins].astype("float64"))
plt.show()

sns.boxplot(data=transformed_df.transpose()[plot_df_ins].astype("float64"))
plt.ylim(0,14)

plt.show()


transformed_df["Class"] = classes



# ------> Colocar legenda nas imagens



# f2 = open("/content/GSE123302_family.soft", "r")
f2 = open("/content/drive/MyDrive/Laura Speggiorin - TCC/GSE123302_family.soft", "r")


data2 = f2.readlines()

begin = np.array(data2)
begin = begin.loc("!platform_table_begin")

end = np.array(data2)
end = end.loc("!platform_table_end")

matrix_str_2 = data2[begin:end]

matrix_str_2

# We want to get TSNE embedding with 2 dimensions
X = transformed_df.drop("Class", axis=1)
Y = classes

from sklearn.metrics import pairwise_distances

distance_matrix = pairwise_distances(X,
                                     metric='euclidean')

plt.imshow(distance_matrix, 'Greys')

n_components = 2
tsne = TSNE(n_components)
tsne_result = tsne.fit_transform(X)

# Plot the result of our TSNE with the label color coded
# A lot of the stuff here is about making the plot look pretty and not TSNE
tsne_result_df = pd.DataFrame({'tsne_1': tsne_result[:,0], 'tsne_2': tsne_result[:,1], 'label': Y})
fig, ax = plt.subplots(1)
sns.scatterplot(x='tsne_1', y='tsne_2', hue='label', data=tsne_result_df, ax=ax,s=120)
lim = (tsne_result.min()-5, tsne_result.max()+5)
ax.set_xlim(lim)
ax.set_ylim(lim)
ax.set_aspect('equal')
ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)

"""Data pre-processing"""

#separar por classe
#0 == desenvolvimento typico, 1 == desenvolvimento não-tipico
isTD = np.array([0 if y=='TD' else 1 for y in classes])

#0 == não TEA, 1 == TEA
isASD = np.array([1 if y=='ASD' else 0 for y in classes])

#dentro de desenvolvimento não-típico 0 == não TEA, 1 == TEA
NonTD_df = transformed_df[isTD == 1]
NonTD_isASD = np.array([1 if y=='ASD' else 0 for y in NonTD_df["Class"]])


("Nr Non-Tipical Development: " + str(len(transformed_df[isTD == 1])),
 "Nr ASD Development: " + str((len(transformed_df[isASD == 1]))))

#nro de folds
K = 5

#separar treino e teste
teste = StratifiedKFold(n_splits=5, random_state=3, shuffle=True)

train_folds = []
test_folds = []

for i, (train_index, test_index) in enumerate(teste.split(transformed_df, isTD, n_splits=K)):

  train_folds.append(train_index)
  test_folds.append(test_index)

#train_folds



#normalizar dados

def min_max_adapt(df_train, df_test, min_list, max_list):

  df_train_ret = np.empty(df_train.shape)
  df_test_ret = np.empty(df_test.shape)

  scaler = MinMaxScaler()
  df_train_ret = scaler.fit_transform(df_train)

  for i in range(df_test.shape[1]):
    min = scaler.data_min_[i]
    max = scaler.data_max_[i]

    row = [(x - min)/(max - min) for x in df_test[:,i]]

    df_test_ret[:,i] = row

  return df_train_ret, df_test_ret

#feature selection

#data augmentation

"""*models*"""

for i in range(K):
  X_train = transformed_df.iloc(train_folds[i])
  X_test = transformed_df.iloc(test_folds[i])

  Y_train = X_train["Class"]
  Y_test = X_test["Class"]

  X_train = X_train.drop["Class"]
  X_test = X_test.drop["Class"]

#nayve bayes

#random forest

#support vector machine

"""Validation"""

